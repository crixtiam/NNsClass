{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Eqn3RtteZei"
      },
      "source": [
        "<div align=\"left\">\n",
        "<p><img alt=\"Sapiencia\" height=\"140px\" src=\"https://ubicua.ingeniaudea.co/pluginfile.php/32974/coursecat/description/RF_RedesNeuronales.png\" align=\"left\" hspace=\"10px\" vspace=\"0px\"></p></div>\n",
        "<div align=\"left\"></div>\n",
        "<div>\n",
        "\n",
        "<br></br>\n",
        "\n",
        "<div align=\"left\">\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "\n",
        "\n",
        "<hr size=10 noshade color=\"#663398\">\n",
        "</p>\n",
        "<p>\n",
        "<img alt=\"CC\" height=\"70px\" src=\"https://creativecommons.org/images/deed/cc_blue_x2.png\" align=\"left\" hspace=\"0px\" vspace=\"0px\">\n",
        "<img alt=\"Attribution\" height=\"70px\" src=\"https://creativecommons.org/images/deed/attribution_icon_blue_x2.png\" align=\"left\" hspace=\"0px\" vspace=\"0px\">\n",
        "<img alt=\"NC\" height=\"70px\" src=\"https://creativecommons.org/images/deed/nc_blue_x2.png\" align=\"left\" hspace=\"0px\" vspace=\"0px\">\n",
        "<img alt=\"SA\" height=\"70px\" src=\"https://creativecommons.org/images/deed/sa_blue_x2.png\" align=\"left\" hspace=\"0px\" vspace=\"0px\">\n",
        "</p>\n",
        "\n",
        "<div align=\"right\">\n",
        "<h1> <b> Por: Cristiam Loaiza </b> </h1>\n",
        "<h2> Ingeniero de datos </h2>\n",
        "<a href=\"mailto:cristiam.loaiza@udea.edu.co\"> ✉ Cristiam Loaiza</a>\n",
        "</div>\n",
        "\n",
        "<br>\n",
        "\n",
        "**El presente material hace parte de la ruta de formación del talento especializado de SAPIENCIA**\n",
        "\n",
        "**Los documentos que utilizaremos en la presente y proximas clases son una mezcla del trabajo de muchos profesores y académicos.**\n",
        "\n",
        "**En caso de utilizar el presente contenido favor citarlo y brindar los créditos respectivos.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvGkmbJKmJgO"
      },
      "source": [
        "<p><a name=\"contents\"></a></p>\n",
        "\n",
        "# Contenido\n",
        "\n",
        "- <a href=\"#Perceptron\">1. Perceptron</a><br>\n",
        "&nbsp;&nbsp; - [1.1 Tipo de Perceptrón](#Perceptron)<br>\n",
        "&nbsp;&nbsp; - [1.2 Analogia](#Analogia)<br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwCSPQiBuLQH"
      },
      "source": [
        "<p><a name=\"Perceptron\"></a></p>\n",
        "\n",
        "# 1) Perceptron\n",
        "\n",
        "[[Contenidos]](#contents)\n",
        "\n",
        "\n",
        "Un Perceptrón es básicamente un modelo de clasificacion lineal, donde usa como función de activación la función de heaviside, la cual recordemos tiene la siguiente forma:\n",
        "\n",
        " $heaviside(x)=\\begin{cases} \n",
        "      0 & x < 0 \\\\\n",
        "      1 & x\\geq 0 \n",
        "   \\end{cases} $\n",
        "\n",
        "\n",
        "Donde el perceptrón es considerado un algoritmo supervisado, cuyos pesos son los $w_{i}$ y el termino $b$ (bias) que podemos ver en las imagenes. \n",
        "\n",
        "<div style=\"text-align: center;\">\n",
        "    <img src=\"https://i.imgur.com/vNWd4os.png\" height=\"300px\"/>\n",
        "</div>\n",
        "\n",
        "\n",
        "Cuando ingresamos nuestros datos, este realiza una suma pesada definda como:\n",
        "\n",
        "$z=\\sum_{i=1}^{m}x_{i}w_{i}+b$\n",
        "\n",
        "Es decir, cada entrada es multiplicada por un peso(el cual normalmente se inicia de forma aleatoria) y los resultados son sumados junto al b.\n",
        "\n",
        "<p><img alt=\"Colaboratory logo\" height=\"300px\" src=\"https://s3.amazonaws.com/stackabuse/media/intro-to-neural-networks-scikit-learn-3.png\" align=\"center\" hspace=\"10px\" vspace=\"0px\"></p>\n",
        "\n",
        "El perceptrón multicapa a diferencia del perceptrón trabaja bien en los casos donde tenemos datos separables no lineales. En las redes neuronales tenemos una capa de entrada, otra de salida y una o multiples capaz ocultas. Como se puede ver las conexiones siempre están dirigidas hacia adelante es decir, las neuronas de una capa se conectan con las neuronas de la siguiente capa.\n",
        "\n",
        "Los pesos dentro de nuestra red neuronal típicamente están expresados como $w_{ij}^{[l]}$, donde \"$l$\" hace referencia a nuestra capa. De forma matricial podemos expresar los valores para la capa $l$ como:\n",
        "\n",
        "\\begin{equation}\n",
        "Z^{[l]}=X^{[l-1]}W^{[l]}+B^{[l]}\n",
        "\\end{equation}\n",
        "\n",
        "Donde $X$ es la matriz de tamaño $m\\times n^{[l-1]}$, $W^{[l]}$ de $n^{[l-1]}\\times n^{[l]}$ y $B$ de $1\\times n^{[l]}$. Donde de nuevo $n^{[l]}$ hace referencia al número de neuronas en la capa $l$.  Donde tenemos que $X^{[l]}$ viene dada por \n",
        "\n",
        "\\begin{equation}\n",
        "X^{[l]}=f^{[l]}(Z^{[l]})\n",
        "\\end{equation}\n",
        "\n",
        "Con $f^{[l]}$ la función de activación de la capa $l$.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<p><a name=\"redesIntro\"></a></p>\n",
        "\n",
        "# 2) Ejemplo red NNS (Perceptron) usando numpy\n",
        "\n",
        "[[Contenidos]](#contents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 445,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 451,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1 - 100\n",
            "[0.28684901 0.49686187 1.22764023 1.43765309]\n",
            "pesos= [0.77426189 0.11656137]\n",
            "error= [-0.28684901 -0.49686187 -1.22764023 -0.43765309]\n",
            "Sesgo : [0.25816411 0.23716282 0.16408498 0.2430837 ]\n",
            "Epoch: 2 - 100\n",
            "[0.25816411 0.35372419 0.93834687 1.13390695]\n",
            "pesos= [0.66703651 0.06779825]\n",
            "error= [-0.25816411 -0.35372419 -0.93834687 -0.13390695]\n",
            "Sesgo : [0.23234769 0.2017904  0.0702503  0.229693  ]\n",
            "Epoch: 3 - 100\n",
            "[0.23234769 0.26958865 0.7372868  0.96452776]\n",
            "pesos= [0.59685505 0.04438661]\n",
            "error= [-0.23234769 -0.26958865 -0.7372868   0.03547224]\n",
            "Sesgo : [ 0.20911293  0.17483153 -0.00347838  0.23324023]\n",
            "Epoch: 4 - 100\n",
            "[0.20911293 0.21921815 0.59337667 0.87448189]\n",
            "pesos= [0.5500692  0.03501661]\n",
            "error= [-0.20911293 -0.21921815 -0.59337667  0.12551811]\n",
            "Sesgo : [ 0.18820163  0.15290972 -0.06281605  0.24579204]\n",
            "Epoch: 5 - 100\n",
            "[0.18820163 0.18792633 0.48725314 0.83087784]\n",
            "pesos= [0.5182561  0.03313619]\n",
            "error= [-0.18820163 -0.18792633 -0.48725314  0.16912216]\n",
            "Sesgo : [ 0.16938147  0.13411709 -0.11154137  0.26270425]\n",
            "Epoch: 6 - 100\n",
            "[0.16938147 0.16725328 0.40671473 0.81409654]\n",
            "pesos= [0.49617497 0.03500121]\n",
            "error= [-0.16938147 -0.16725328 -0.40671473  0.18590346]\n",
            "Sesgo : [ 0.15244332  0.11739176 -0.15221284  0.2812946 ]\n",
            "Epoch: 7 - 100\n",
            "[0.15244332 0.15239297 0.34396213 0.81247078]\n",
            "pesos= [0.48053168 0.03851483]\n",
            "error= [-0.15244332 -0.15239297 -0.34396213  0.18752922]\n",
            "Sesgo : [ 0.13719899  0.10215246 -0.18660905  0.30004752]\n",
            "Epoch: 8 - 100\n",
            "[0.13719899 0.1406673  0.29392263 0.81909403]\n",
            "pesos= [0.46923001 0.0425387 ]\n",
            "error= [-0.13719899 -0.1406673  -0.29392263  0.18090597]\n",
            "Sesgo : [ 0.12347909  0.08808573 -0.21600131  0.31813812]\n",
            "Epoch: 9 - 100\n",
            "[0.12347909 0.13062443 0.2532287  0.82990683]\n",
            "pesos= [0.46091646 0.04648557]\n",
            "error= [-0.12347909 -0.13062443 -0.2532287   0.17009317]\n",
            "Sesgo : [ 0.11113118  0.07502329 -0.24132418  0.33514743]\n",
            "Epoch: 10 - 100\n",
            "[0.11113118 0.12150886 0.21959228 0.84254947]\n",
            "pesos= [0.45470229 0.05007974]\n",
            "error= [-0.11113118 -0.12150886 -0.21959228  0.15745053]\n",
            "Sesgo : [ 0.10001806  0.0628724  -0.26328341  0.35089249]\n",
            "Epoch: 11 - 100\n",
            "[0.10001806 0.11295214 0.19141887 0.85567451]\n",
            "pesos= [0.44999295 0.05321708]\n",
            "error= [-0.10001806 -0.11295214 -0.19141887  0.14432549]\n",
            "Sesgo : [ 0.09001626  0.05157719 -0.2824253   0.36532504]\n",
            "Epoch: 12 - 100\n",
            "[0.09001626 0.10479426 0.16756765 0.86853506]\n",
            "pesos= [0.44638268 0.05588414]\n",
            "error= [-0.09001626 -0.10479426 -0.16756765  0.13146494]\n",
            "Sesgo : [ 0.08101463  0.04109776 -0.29918206  0.37847153]\n",
            "Epoch: 13 - 100\n",
            "[0.08101463 0.09698191 0.14720061 0.88073835]\n",
            "pesos= [0.44358878 0.05811212]\n",
            "error= [-0.08101463 -0.09698191 -0.14720061  0.11926165]\n",
            "Sesgo : [ 0.07291317  0.03139957 -0.31390213  0.39039769]\n",
            "Epoch: 14 - 100\n",
            "[0.07291317 0.08951169 0.12968665 0.89209859]\n",
            "pesos= [0.44141026 0.05995109]\n",
            "error= [-0.07291317 -0.08951169 -0.12968665  0.10790141]\n",
            "Sesgo : [ 0.06562185  0.0224484  -0.32687079  0.40118784]\n",
            "Epoch: 15 - 100\n",
            "[0.06562185 0.08239949 0.11453946 0.90254918]\n",
            "pesos= [0.43970139 0.06145622]\n",
            "error= [-0.06562185 -0.08239949 -0.11453946  0.09745082]\n",
            "Sesgo : [ 0.05905967  0.01420845 -0.33832474  0.41093292]\n",
            "Epoch: 16 - 100\n",
            "[0.05905967 0.07566468 0.10137665 0.91209053]\n",
            "pesos= [0.43835467 0.0626807 ]\n",
            "error= [-0.05905967 -0.07566468 -0.10137665  0.08790947]\n",
            "Sesgo : [ 0.0531537   0.00664199 -0.3484624   0.41972386]\n",
            "Epoch: 17 - 100\n",
            "[0.0531537  0.06932269 0.08989227 0.92075924]\n",
            "pesos= [0.43728952 0.06367251]\n",
            "error= [-0.0531537  -0.06932269 -0.08989227  0.07924076]\n",
            "Sesgo : [ 4.78383299e-02 -2.90282868e-04 -3.57451630e-01  4.27647940e-01]\n",
            "Epoch: 18 - 100\n",
            "[0.04783833 0.06338223 0.07983789 0.92860997]\n",
            "pesos= [0.43644474 0.06447329]\n",
            "error= [-0.04783833 -0.06338223 -0.07983789  0.07139003]\n",
            "Sesgo : [ 0.0430545  -0.00662851 -0.36543542  0.43478694]\n",
            "Epoch: 19 - 100\n",
            "[0.0430545  0.05784478 0.07100932 0.93570497]\n",
            "pesos= [0.43577331 0.06511831]\n",
            "error= [-0.0430545  -0.05784478 -0.07100932  0.06429503]\n",
            "Sesgo : [ 0.03874905 -0.01241298 -0.37253635  0.44121645]\n",
            "Epoch: 20 - 100\n",
            "[0.03874905 0.05270533 0.06323696 0.94210807]\n",
            "pesos= [0.4352388  0.06563697]\n",
            "error= [-0.03874905 -0.05270533 -0.06323696  0.05789193]\n",
            "Sesgo : [ 0.03487414 -0.01768352 -0.37886005  0.44700564]\n",
            "Epoch: 21 - 100\n",
            "[0.03487414 0.04795346 0.05637876 0.94788142]\n",
            "pesos= [0.43481279 0.06605349]\n",
            "error= [-0.03487414 -0.04795346 -0.05637876  0.05211858]\n",
            "Sesgo : [ 0.03138673 -0.02247886 -0.38449792  0.4522175 ]\n",
            "Epoch: 22 - 100\n",
            "[0.03138673 0.04357462 0.05031486 0.95308377]\n",
            "pesos= [0.43447292 0.06638765]\n",
            "error= [-0.03138673 -0.04357462 -0.05031486  0.04691623]\n",
            "Sesgo : [ 0.02824806 -0.02683633 -0.38952941  0.45690912]\n",
            "Epoch: 23 - 100\n",
            "[0.02824806 0.03955132 0.04494351 0.95776969]\n",
            "pesos= [0.4342016  0.06665555]\n",
            "error= [-0.02824806 -0.03955132 -0.04494351  0.04223031]\n",
            "Sesgo : [ 0.02542325 -0.03079146 -0.39402376  0.46113215]\n",
            "Epoch: 24 - 100\n",
            "[0.02542325 0.03586409 0.04017784 0.9619893 ]\n",
            "pesos= [0.43398489 0.06687021]\n",
            "error= [-0.02542325 -0.03586409 -0.04017784  0.0380107 ]\n",
            "Sesgo : [ 0.02288092 -0.03437787 -0.39804154  0.46493322]\n",
            "Epoch: 25 - 100\n",
            "[0.02288092 0.03249234 0.03594334 0.96578832]\n",
            "pesos= [0.43381172 0.06704214]\n",
            "error= [-0.02288092 -0.03249234 -0.03594334  0.03421168]\n",
            "Sesgo : [ 0.02059283 -0.0376271  -0.40163588  0.46835439]\n",
            "Epoch: 26 - 100\n",
            "[0.02059283 0.02941504 0.03217584 0.96920825]\n",
            "pesos= [0.43367331 0.06717981]\n",
            "error= [-0.02059283 -0.02941504 -0.03217584  0.03079175]\n",
            "Sesgo : [ 0.01853355 -0.0405686  -0.40485346  0.47143356]\n",
            "Epoch: 27 - 100\n",
            "[0.01853355 0.02661121 0.02881985 0.97228669]\n",
            "pesos= [0.43356266 0.06729002]\n",
            "error= [-0.01853355 -0.02661121 -0.02881985  0.02771331]\n",
            "Sesgo : [ 0.01668019 -0.04322973 -0.40773545  0.4742049 ]\n",
            "Epoch: 28 - 100\n",
            "[0.01668019 0.0240603  0.02582721 0.97505758]\n",
            "pesos= [0.43347418 0.06737823]\n",
            "error= [-0.01668019 -0.0240603  -0.02582721  0.02494242]\n",
            "Sesgo : [ 0.01501217 -0.04563575 -0.41031817  0.47669914]\n",
            "Epoch: 29 - 100\n",
            "[0.01501217 0.02174248 0.02315601 0.97755155]\n",
            "pesos= [0.43340342 0.06744883]\n",
            "error= [-0.01501217 -0.02174248 -0.02315601  0.02244845]\n",
            "Sesgo : [ 0.01351096 -0.04781    -0.41263377  0.47894398]\n",
            "Epoch: 30 - 100\n",
            "[0.01351096 0.01963883 0.02076965 0.97979624]\n",
            "pesos= [0.43334683 0.06750532]\n",
            "error= [-0.01351096 -0.01963883 -0.02076965  0.02020376]\n",
            "Sesgo : [ 0.01215986 -0.04977389 -0.41471074  0.48096436]\n",
            "Epoch: 31 - 100\n",
            "[0.01215986 0.01773144 0.0186361  0.98181652]\n",
            "pesos= [0.43330157 0.06755053]\n",
            "error= [-0.01215986 -0.01773144 -0.0186361   0.01818348]\n",
            "Sesgo : [ 0.01094388 -0.05154703 -0.41657435  0.48278271]\n",
            "Epoch: 32 - 100\n",
            "[0.01094388 0.0160035  0.01672723 0.98363481]\n",
            "pesos= [0.43326537 0.0675867 ]\n",
            "error= [-0.01094388 -0.0160035  -0.01672723  0.01636519]\n",
            "Sesgo : [ 0.00984949 -0.05314738 -0.41824707  0.48441923]\n",
            "Epoch: 33 - 100\n",
            "[0.00984949 0.01443932 0.0150183  0.98527129]\n",
            "pesos= [0.43323641 0.06761564]\n",
            "error= [-0.00984949 -0.01443932 -0.0150183   0.01472871]\n",
            "Sesgo : [ 0.00886454 -0.05459131 -0.4197489   0.4858921 ]\n",
            "Epoch: 34 - 100\n",
            "[0.00886454 0.01302433 0.01348751 0.98674414]\n",
            "pesos= [0.43321324 0.06763879]\n",
            "error= [-0.00886454 -0.01302433 -0.01348751  0.01325586]\n",
            "Sesgo : [ 0.00797809 -0.05589374 -0.42109765  0.48721768]\n",
            "Epoch: 35 - 100\n",
            "[0.00797809 0.01174505 0.01211559 0.98806972]\n",
            "pesos= [0.43319471 0.06765731]\n",
            "error= [-0.00797809 -0.01174505 -0.01211559  0.01193028]\n",
            "Sesgo : [ 0.00718028 -0.05706825 -0.42230921  0.48841071]\n",
            "Epoch: 36 - 100\n",
            "[0.00718028 0.01058907 0.0108855  0.98926274]\n",
            "pesos= [0.43317989 0.06767213]\n",
            "error= [-0.00718028 -0.01058907 -0.0108855   0.01073726]\n",
            "Sesgo : [ 0.00646225 -0.05812716 -0.42339776  0.48948444]\n",
            "Epoch: 37 - 100\n",
            "[0.00646225 0.00954498 0.00978213 0.99033646]\n",
            "pesos= [0.43316803 0.06768399]\n",
            "error= [-0.00646225 -0.00954498 -0.00978213  0.00966354]\n",
            "Sesgo : [ 0.00581602 -0.05908165 -0.42437597  0.49045079]\n",
            "Epoch: 38 - 100\n",
            "[0.00581602 0.00860234 0.00879206 0.99130281]\n",
            "pesos= [0.43315854 0.06769347]\n",
            "error= [-0.00581602 -0.00860234 -0.00879206  0.00869719]\n",
            "Sesgo : [ 0.00523442 -0.05994189 -0.42525518  0.49132051]\n",
            "Epoch: 39 - 100\n",
            "[0.00523442 0.00775159 0.00790337 0.99217253]\n",
            "pesos= [0.43315095 0.06770106]\n",
            "error= [-0.00523442 -0.00775159 -0.00790337  0.00782747]\n",
            "Sesgo : [ 0.00471098 -0.06071705 -0.42604551  0.49210326]\n",
            "Epoch: 40 - 100\n",
            "[0.00471098 0.00698402 0.00710544 0.99295527]\n",
            "pesos= [0.43314488 0.06770713]\n",
            "error= [-0.00471098 -0.00698402 -0.00710544  0.00704473]\n",
            "Sesgo : [ 0.00423988 -0.06141545 -0.42675606  0.49280773]\n",
            "Epoch: 41 - 100\n",
            "[0.00423988 0.00629169 0.00638882 0.99365975]\n",
            "pesos= [0.43314003 0.06771199]\n",
            "error= [-0.00423988 -0.00629169 -0.00638882  0.00634025]\n",
            "Sesgo : [ 0.00381589 -0.06204462 -0.42739494  0.49344176]\n",
            "Epoch: 42 - 100\n",
            "[0.00381589 0.00566737 0.00574508 0.99429377]\n",
            "pesos= [0.43313614 0.06771588]\n",
            "error= [-0.00381589 -0.00566737 -0.00574508  0.00570623]\n",
            "Sesgo : [ 0.0034343  -0.06261135 -0.42796945  0.49401238]\n",
            "Epoch: 43 - 100\n",
            "[0.0034343  0.00510452 0.00516669 0.99486439]\n",
            "pesos= [0.43313303 0.06771898]\n",
            "error= [-0.0034343  -0.00510452 -0.00516669  0.00513561]\n",
            "Sesgo : [ 0.00309087 -0.06312181 -0.42848612  0.49452594]\n",
            "Epoch: 44 - 100\n",
            "[0.00309087 0.00459718 0.00464691 0.99537795]\n",
            "pesos= [0.43313054 0.06772147]\n",
            "error= [-0.00309087 -0.00459718 -0.00464691  0.00462205]\n",
            "Sesgo : [ 0.00278179 -0.06358152 -0.42895081  0.49498814]\n",
            "Epoch: 45 - 100\n",
            "[0.00278179 0.00413995 0.00417973 0.99584016]\n",
            "pesos= [0.43312856 0.06772346]\n",
            "error= [-0.00278179 -0.00413995 -0.00417973  0.00415984]\n",
            "Sesgo : [ 0.00250361 -0.06399552 -0.42936878  0.49540413]\n",
            "Epoch: 46 - 100\n",
            "[0.00250361 0.00372794 0.00375977 0.99625614]\n",
            "pesos= [0.43312696 0.06772505]\n",
            "error= [-0.00250361 -0.00372794 -0.00375977  0.00374386]\n",
            "Sesgo : [ 0.00225325 -0.06436831 -0.42974476  0.49577851]\n",
            "Epoch: 47 - 100\n",
            "[0.00225325 0.00335674 0.0033822  0.99663053]\n",
            "pesos= [0.43312569 0.06772633]\n",
            "error= [-0.00225325 -0.00335674 -0.0033822   0.00336947]\n",
            "Sesgo : [ 0.00202792 -0.06470399 -0.43008298  0.49611546]\n",
            "Epoch: 48 - 100\n",
            "[0.00202792 0.00302234 0.00304271 0.99696748]\n",
            "pesos= [0.43312467 0.06772734]\n",
            "error= [-0.00202792 -0.00302234 -0.00304271  0.00303252]\n",
            "Sesgo : [ 0.00182513 -0.06500622 -0.43038725  0.49641871]\n",
            "Epoch: 49 - 100\n",
            "[0.00182513 0.00272112 0.00273742 0.99727073]\n",
            "pesos= [0.43312386 0.06772816]\n",
            "error= [-0.00182513 -0.00272112 -0.00273742  0.00272927]\n",
            "Sesgo : [ 0.00164262 -0.06527833 -0.43066099  0.49669164]\n",
            "Epoch: 50 - 100\n",
            "[0.00164262 0.00244983 0.00246286 0.99754366]\n",
            "pesos= [0.43312321 0.06772881]\n",
            "error= [-0.00164262 -0.00244983 -0.00246286  0.00245634]\n",
            "Sesgo : [ 0.00147836 -0.06552332 -0.43090728  0.49693727]\n",
            "Epoch: 51 - 100\n",
            "[0.00147836 0.0022055  0.00221593 0.99778929]\n",
            "pesos= [0.43312268 0.06772933]\n",
            "error= [-0.00147836 -0.0022055  -0.00221593  0.00221071]\n",
            "Sesgo : [ 0.00133052 -0.06574386 -0.43112887  0.49715835]\n",
            "Epoch: 52 - 100\n",
            "[0.00133052 0.00198547 0.00199381 0.99801036]\n",
            "pesos= [0.43312227 0.06772975]\n",
            "error= [-0.00133052 -0.00198547 -0.00199381  0.00198964]\n",
            "Sesgo : [ 0.00119747 -0.06594241 -0.43132825  0.49735731]\n",
            "Epoch: 53 - 100\n",
            "[0.00119747 0.00178734 0.00179401 0.99820932]\n",
            "pesos= [0.43312193 0.06773008]\n",
            "error= [-0.00119747 -0.00178734 -0.00179401  0.00179068]\n",
            "Sesgo : [ 0.00107772 -0.06612115 -0.43150765  0.49753638]\n",
            "Epoch: 54 - 100\n",
            "[0.00107772 0.00160894 0.00161428 0.99838839]\n",
            "pesos= [0.43312167 0.06773035]\n",
            "error= [-0.00107772 -0.00160894 -0.00161428  0.00161161]\n",
            "Sesgo : [ 0.00096995 -0.06628204 -0.43166908  0.49769754]\n",
            "Epoch: 55 - 100\n",
            "[9.69948909e-04 1.44831087e-03 1.45258301e-03 9.98549553e-01]\n",
            "pesos= [0.43312145 0.06773056]\n",
            "error= [-0.00096995 -0.00144831 -0.00145258  0.00145045]\n",
            "Sesgo : [ 0.00087295 -0.06642687 -0.43181434  0.49784258]\n",
            "Epoch: 56 - 100\n",
            "[8.72954018e-04 1.30369339e-03 1.30711110e-03 9.98694598e-01]\n",
            "pesos= [0.43312128 0.06773073]\n",
            "error= [-0.00087295 -0.00130369 -0.00130711  0.0013054 ]\n",
            "Sesgo : [ 0.00078566 -0.06655724 -0.43194505  0.49797312]\n",
            "Epoch: 57 - 100\n",
            "[7.85658616e-04 1.17349494e-03 1.17622911e-03 9.98825138e-01]\n",
            "pesos= [0.43312114 0.06773087]\n",
            "error= [-0.00078566 -0.00117349 -0.00117623  0.00117486]\n",
            "Sesgo : [ 0.00070709 -0.06667459 -0.43206268  0.49809061]\n",
            "Epoch: 58 - 100\n",
            "[7.07092754e-04 1.05628215e-03 1.05846949e-03 9.98942624e-01]\n",
            "pesos= [0.43312104 0.06773098]\n",
            "error= [-0.00070709 -0.00105628 -0.00105847  0.00105738]\n",
            "Sesgo : [ 0.00063638 -0.06678022 -0.43216852  0.49819635]\n",
            "Epoch: 59 - 100\n",
            "[6.36383479e-04 9.50763305e-04 9.52513171e-04 9.99048362e-01]\n",
            "pesos= [0.43312095 0.06773107]\n",
            "error= [-0.00063638 -0.00095076 -0.00095251  0.00095164]\n",
            "Sesgo : [ 0.00057275 -0.06687529 -0.43226377  0.49829151]\n",
            "Epoch: 60 - 100\n",
            "[5.72745131e-04 8.55774467e-04 8.57174361e-04 9.99143526e-01]\n",
            "pesos= [0.43312088 0.06773114]\n",
            "error= [-0.00057275 -0.00085577 -0.00085717  0.00085647]\n",
            "Sesgo : [ 0.00051547 -0.06696087 -0.43234949  0.49837716]\n",
            "Epoch: 61 - 100\n",
            "[5.15470618e-04 7.70267015e-04 7.71386930e-04 9.99229173e-01]\n",
            "pesos= [0.43312082 0.06773119]\n",
            "error= [-0.00051547 -0.00077027 -0.00077139  0.00077083]\n",
            "Sesgo : [ 4.63923556e-04 -6.70378976e-02 -4.32426629e-01  4.98454240e-01]\n",
            "Epoch: 62 - 100\n",
            "[4.63923556e-04 6.93296310e-04 6.94192241e-04 9.99306256e-01]\n",
            "pesos= [0.43312078 0.06773124]\n",
            "error= [-0.00046392 -0.0006933  -0.00069419  0.00069374]\n",
            "Sesgo : [ 4.17531200e-04 -6.71072273e-02 -4.32496049e-01  4.98523615e-01]\n",
            "Epoch: 63 - 100\n",
            "[4.17531200e-04 6.24011475e-04 6.24728220e-04 9.99375630e-01]\n",
            "pesos= [0.43312074 0.06773127]\n",
            "error= [-0.00041753 -0.00062401 -0.00062473  0.00062437]\n",
            "Sesgo : [ 3.75778080e-04 -6.71696284e-02 -4.32558521e-01  4.98586052e-01]\n",
            "Epoch: 64 - 100\n",
            "[3.75778080e-04 5.61646165e-04 5.62219561e-04 9.99438067e-01]\n",
            "pesos= [0.43312071 0.0677313 ]\n",
            "error= [-0.00037578 -0.00056165 -0.00056222  0.00056193]\n",
            "Sesgo : [ 3.38200272e-04 -6.72257930e-02 -4.32614743e-01  4.98642245e-01]\n",
            "Epoch: 65 - 100\n",
            "[3.38200272e-04 5.05510218e-04 5.05968935e-04 9.99494260e-01]\n",
            "pesos= [0.43312069 0.06773133]\n",
            "error= [-0.0003382  -0.00050551 -0.00050597  0.00050574]\n",
            "Sesgo : [ 3.04380245e-04 -6.72763441e-02 -4.32665340e-01  4.98692819e-01]\n",
            "Epoch: 66 - 100\n",
            "[3.04380245e-04 4.54982132e-04 4.55349106e-04 9.99544834e-01]\n",
            "pesos= [0.43312067 0.06773134]\n",
            "error= [-0.00030438 -0.00045498 -0.00045535  0.00045517]\n",
            "Sesgo : [ 2.73942221e-04 -6.73218423e-02 -4.32710875e-01  4.98738335e-01]\n",
            "Epoch: 67 - 100\n",
            "[2.73942221e-04 4.09502268e-04 4.09795847e-04 9.99590351e-01]\n",
            "pesos= [0.43312066 0.06773136]\n",
            "error= [-0.00027394 -0.0004095  -0.0004098   0.00040965]\n",
            "Sesgo : [ 2.46547999e-04 -6.73627925e-02 -4.32751855e-01  4.98779300e-01]\n",
            "Epoch: 68 - 100\n",
            "[2.46547999e-04 3.68566720e-04 3.68801583e-04 9.99631316e-01]\n",
            "pesos= [0.43312064 0.06773137]\n",
            "error= [-0.00024655 -0.00036857 -0.0003688   0.00036868]\n",
            "Sesgo : [ 2.21893199e-04 -6.73996492e-02 -4.32788735e-01  4.98816169e-01]\n",
            "Epoch: 69 - 100\n",
            "[2.21893199e-04 3.31721791e-04 3.31909682e-04 9.99668184e-01]\n",
            "pesos= [0.43312064 0.06773138]\n",
            "error= [-0.00022189 -0.00033172 -0.00033191  0.00033182]\n",
            "Sesgo : [ 1.99703879e-04 -6.74328213e-02 -4.32821926e-01  4.98849350e-01]\n",
            "Epoch: 70 - 100\n",
            "[1.99703879e-04 2.98559006e-04 2.98709319e-04 9.99701366e-01]\n",
            "pesos= [0.43312063 0.06773139]\n",
            "error= [-0.0001997  -0.00029856 -0.00029871  0.00029863]\n",
            "Sesgo : [ 1.79733491e-04 -6.74626772e-02 -4.32851797e-01  4.98879214e-01]\n",
            "Epoch: 71 - 100\n",
            "[1.79733491e-04 2.68710621e-04 2.68830871e-04 9.99731229e-01]\n",
            "pesos= [0.43312062 0.06773139]\n",
            "error= [-0.00017973 -0.00026871 -0.00026883  0.00026877]\n",
            "Sesgo : [ 1.61760142e-04 -6.74895483e-02 -4.32878680e-01  4.98906091e-01]\n",
            "Epoch: 72 - 100\n",
            "[1.61760142e-04 2.41845572e-04 2.41941772e-04 9.99758106e-01]\n",
            "pesos= [0.43312062 0.0677314 ]\n",
            "error= [-0.00016176 -0.00024185 -0.00024194  0.00024189]\n",
            "Sesgo : [ 1.45584128e-04 -6.75137329e-02 -4.32902874e-01  4.98930280e-01]\n",
            "Epoch: 73 - 100\n",
            "[1.45584128e-04 2.17665825e-04 2.17742785e-04 9.99782296e-01]\n",
            "pesos= [0.43312061 0.0677314 ]\n",
            "error= [-0.00014558 -0.00021767 -0.00021774  0.0002177 ]\n",
            "Sesgo : [ 1.31025715e-04 -6.75354994e-02 -4.32924648e-01  4.98952050e-01]\n",
            "Epoch: 74 - 100\n",
            "[1.31025715e-04 1.95903090e-04 1.95964658e-04 9.99804066e-01]\n",
            "pesos= [0.43312061 0.06773141]\n",
            "error= [-0.00013103 -0.0001959  -0.00019596  0.00019593]\n",
            "Sesgo : [ 1.17923143e-04 -6.75550898e-02 -4.32944245e-01  4.98971644e-01]\n",
            "Epoch: 75 - 100\n",
            "[1.17923143e-04 1.76315860e-04 1.76365114e-04 9.99823660e-01]\n",
            "pesos= [0.43312061 0.06773141]\n",
            "error= [-0.00011792 -0.00017632 -0.00017637  0.00017634]\n",
            "Sesgo : [ 1.06130829e-04 -6.75727213e-02 -4.32961881e-01  4.98989278e-01]\n",
            "Epoch: 76 - 100\n",
            "[1.06130829e-04 1.58686736e-04 1.58726140e-04 9.99841294e-01]\n",
            "pesos= [0.43312061 0.06773141]\n",
            "error= [-0.00010613 -0.00015869 -0.00015873  0.00015871]\n",
            "Sesgo : [ 9.55177462e-05 -6.75885900e-02 -4.32977754e-01  4.99005149e-01]\n",
            "Epoch: 77 - 100\n",
            "[9.55177462e-05 1.42820033e-04 1.42851556e-04 9.99857164e-01]\n",
            "pesos= [0.4331206  0.06773141]\n",
            "error= [-9.55177462e-05 -1.42820033e-04 -1.42851556e-04  1.42835794e-04]\n",
            "Sesgo : [ 8.59659716e-05 -6.76028720e-02 -4.32992039e-01  4.99019432e-01]\n",
            "Epoch: 78 - 100\n",
            "[8.59659716e-05 1.28539606e-04 1.28564824e-04 9.99871448e-01]\n",
            "pesos= [0.4331206  0.06773141]\n",
            "error= [-8.59659716e-05 -1.28539606e-04 -1.28564824e-04  1.28552215e-04]\n",
            "Sesgo : [ 7.73693744e-05 -6.76157260e-02 -4.33004896e-01  4.99032287e-01]\n",
            "Epoch: 79 - 100\n",
            "[7.73693744e-05 1.15686906e-04 1.15707081e-04 9.99884303e-01]\n",
            "pesos= [0.4331206  0.06773141]\n",
            "error= [-7.73693744e-05 -1.15686906e-04 -1.15707081e-04  1.15696993e-04]\n",
            "Sesgo : [ 6.96324370e-05 -6.76272947e-02 -4.33016466e-01  4.99043857e-01]\n",
            "Epoch: 80 - 100\n",
            "[6.96324370e-05 1.04119224e-04 1.04135364e-04 9.99895873e-01]\n",
            "pesos= [0.4331206  0.06773141]\n",
            "error= [-6.96324370e-05 -1.04119224e-04 -1.04135364e-04  1.04127294e-04]\n",
            "Sesgo : [ 6.26691933e-05 -6.76377066e-02 -4.33026880e-01  4.99054270e-01]\n",
            "Epoch: 81 - 100\n",
            "[6.26691933e-05 9.37081087e-05 9.37210205e-05 9.99906285e-01]\n",
            "pesos= [0.4331206  0.06773142]\n",
            "error= [-6.26691933e-05 -9.37081087e-05 -9.37210205e-05  9.37145646e-05]\n",
            "Sesgo : [ 5.64022739e-05 -6.76470774e-02 -4.33036252e-01  4.99063641e-01]\n",
            "Epoch: 82 - 100\n",
            "[5.64022739e-05 8.43379434e-05 8.43482728e-05 9.99915657e-01]\n",
            "pesos= [0.4331206  0.06773142]\n",
            "error= [-5.64022739e-05 -8.43379434e-05 -8.43482728e-05  8.43431081e-05]\n",
            "Sesgo : [ 5.07620465e-05 -6.76555112e-02 -4.33044687e-01  4.99072076e-01]\n",
            "Epoch: 83 - 100\n",
            "[5.07620465e-05 7.59046656e-05 7.59129291e-05 9.99924091e-01]\n",
            "pesos= [0.4331206  0.06773142]\n",
            "error= [-5.07620465e-05 -7.59046656e-05 -7.59129291e-05  7.59087973e-05]\n",
            "Sesgo : [ 4.56858419e-05 -6.76631017e-02 -4.33052278e-01  4.99079666e-01]\n",
            "Epoch: 84 - 100\n",
            "[4.56858419e-05 6.83146122e-05 6.83212230e-05 9.99931682e-01]\n",
            "pesos= [0.4331206  0.06773142]\n",
            "error= [-4.56858419e-05 -6.83146122e-05 -6.83212230e-05  6.83179176e-05]\n",
            "Sesgo : [ 4.11172577e-05 -6.76699331e-02 -4.33059110e-01  4.99086498e-01]\n",
            "Epoch: 85 - 100\n",
            "[4.11172577e-05 6.14834815e-05 6.14887702e-05 9.99938514e-01]\n",
            "pesos= [0.4331206  0.06773142]\n",
            "error= [-4.11172577e-05 -6.14834815e-05 -6.14887702e-05  6.14861258e-05]\n",
            "Sesgo : [ 3.70055319e-05 -6.76760815e-02 -4.33065259e-01  4.99092647e-01]\n",
            "Epoch: 86 - 100\n",
            "[3.70055319e-05 5.53353978e-05 5.53396287e-05 9.99944662e-01]\n",
            "pesos= [0.4331206  0.06773142]\n",
            "error= [-3.70055319e-05 -5.53353978e-05 -5.53396287e-05  5.53375132e-05]\n",
            "Sesgo : [ 3.33049787e-05 -6.76816150e-02 -4.33070793e-01  4.99098181e-01]\n",
            "Epoch: 87 - 100\n",
            "[3.33049787e-05 4.98020696e-05 4.98054543e-05 9.99950196e-01]\n",
            "pesos= [0.4331206  0.06773142]\n",
            "error= [-3.33049787e-05 -4.98020696e-05 -4.98054543e-05  4.98037619e-05]\n",
            "Sesgo : [ 2.99744809e-05 -6.76865952e-02 -4.33075774e-01  4.99103161e-01]\n",
            "Epoch: 88 - 100\n",
            "[2.99744809e-05 4.48220318e-05 4.48247396e-05 9.99955177e-01]\n",
            "pesos= [0.4331206  0.06773142]\n",
            "error= [-2.99744809e-05 -4.48220318e-05 -4.48247396e-05  4.48233857e-05]\n",
            "Sesgo : [ 2.69770328e-05 -6.76910774e-02 -4.33080256e-01  4.99107643e-01]\n",
            "Epoch: 89 - 100\n",
            "[2.69770328e-05 4.03399640e-05 4.03421303e-05 9.99959659e-01]\n",
            "pesos= [0.4331206  0.06773142]\n",
            "error= [-2.69770328e-05 -4.03399640e-05 -4.03421303e-05  4.03410472e-05]\n",
            "Sesgo : [ 2.42793295e-05 -6.76951114e-02 -4.33084290e-01  4.99111677e-01]\n",
            "Epoch: 90 - 100\n",
            "[2.42793295e-05 3.63060760e-05 3.63078089e-05 9.99963693e-01]\n",
            "pesos= [0.4331206  0.06773142]\n",
            "error= [-2.42793295e-05 -3.63060760e-05 -3.63078089e-05  3.63069424e-05]\n",
            "Sesgo : [ 2.18513965e-05 -6.76987420e-02 -4.33087921e-01  4.99115308e-01]\n",
            "Epoch: 91 - 100\n",
            "[2.18513965e-05 3.26755550e-05 3.26769414e-05 9.99967324e-01]\n",
            "pesos= [0.4331206  0.06773142]\n",
            "error= [-2.18513965e-05 -3.26755550e-05 -3.26769414e-05  3.26762482e-05]\n",
            "Sesgo : [ 1.96662569e-05 -6.77020096e-02 -4.33091189e-01  4.99118576e-01]\n",
            "Epoch: 92 - 100\n",
            "[1.96662569e-05 2.94080688e-05 2.94091779e-05 9.99970591e-01]\n",
            "pesos= [0.4331206  0.06773142]\n",
            "error= [-1.96662569e-05 -2.94080688e-05 -2.94091779e-05  2.94086234e-05]\n",
            "Sesgo : [ 1.76996312e-05 -6.77049504e-02 -4.33094130e-01  4.99121517e-01]\n",
            "Epoch: 93 - 100\n",
            "[1.76996312e-05 2.64673174e-05 2.64682047e-05 9.99973532e-01]\n",
            "pesos= [0.4331206  0.06773142]\n",
            "error= [-1.76996312e-05 -2.64673174e-05 -2.64682047e-05  2.64677610e-05]\n",
            "Sesgo : [ 1.59296681e-05 -6.77075971e-02 -4.33096777e-01  4.99124163e-01]\n",
            "Epoch: 94 - 100\n",
            "[1.59296681e-05 2.38206300e-05 2.38213399e-05 9.99976179e-01]\n",
            "pesos= [0.4331206  0.06773142]\n",
            "error= [-1.59296681e-05 -2.38206300e-05 -2.38213399e-05  2.38209849e-05]\n",
            "Sesgo : [ 1.43367013e-05 -6.77099792e-02 -4.33099159e-01  4.99126545e-01]\n",
            "Epoch: 95 - 100\n",
            "[1.43367013e-05 2.14386025e-05 2.14391704e-05 9.99978561e-01]\n",
            "pesos= [0.4331206  0.06773142]\n",
            "error= [-1.43367013e-05 -2.14386025e-05 -2.14391704e-05  2.14388864e-05]\n",
            "Sesgo : [ 1.29030311e-05 -6.77121230e-02 -4.33101303e-01  4.99128689e-01]\n",
            "Epoch: 96 - 100\n",
            "[1.29030311e-05 1.92947707e-05 1.92952249e-05 9.99980705e-01]\n",
            "pesos= [0.4331206  0.06773142]\n",
            "error= [-1.29030311e-05 -1.92947707e-05 -1.92952249e-05  1.92949978e-05]\n",
            "Sesgo : [ 1.16127280e-05 -6.77140525e-02 -4.33103232e-01  4.99130619e-01]\n",
            "Epoch: 97 - 100\n",
            "[1.16127280e-05 1.73653163e-05 1.73656797e-05 9.99982635e-01]\n",
            "pesos= [0.4331206  0.06773142]\n",
            "error= [-1.16127280e-05 -1.73653163e-05 -1.73656797e-05  1.73654980e-05]\n",
            "Sesgo : [ 1.04514552e-05 -6.77157891e-02 -4.33104969e-01  4.99132355e-01]\n",
            "Epoch: 98 - 100\n",
            "[1.04514552e-05 1.56288028e-05 1.56290936e-05 9.99984371e-01]\n",
            "pesos= [0.4331206  0.06773142]\n",
            "error= [-1.04514552e-05 -1.56288028e-05 -1.56290936e-05  1.56289482e-05]\n",
            "Sesgo : [ 9.40630971e-06 -6.77173519e-02 -4.33106532e-01  4.99133918e-01]\n",
            "Epoch: 99 - 100\n",
            "[9.40630971e-06 1.40659371e-05 1.40661697e-05 9.99985934e-01]\n",
            "pesos= [0.4331206  0.06773142]\n",
            "error= [-9.40630971e-06 -1.40659371e-05 -1.40661697e-05  1.40660534e-05]\n",
            "Sesgo : [ 8.46567874e-06 -6.77187585e-02 -4.33107938e-01  4.99135325e-01]\n",
            "Epoch: 100 - 100\n",
            "[8.46567874e-06 1.26593550e-05 1.26595411e-05 9.99987341e-01]\n",
            "pesos= [0.4331206  0.06773142]\n",
            "error= [-8.46567874e-06 -1.26593550e-05 -1.26595411e-05  1.26594481e-05]\n",
            "Sesgo : [ 7.61911086e-06 -6.77200245e-02 -4.33109204e-01  4.99136591e-01]\n"
          ]
        }
      ],
      "source": [
        "###Entradas\n",
        "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "#Salidas esperadas\n",
        "Y = np.array([0,0,0,1])\n",
        "\n",
        "w = np.random.rand(2)\n",
        "b=  np.random.rand(1)\n",
        "\n",
        "\n",
        "lr = 0.1\n",
        "epoch = 100\n",
        "\n",
        "for i in range(epoch):\n",
        "    print(f\"Epoch: {i+1} - {epoch}\")\n",
        "    y_h = np.dot(X,w) + b\n",
        "    print(y_h)\n",
        "    error = Y - y_h\n",
        "\n",
        "    w = w + lr * np.dot(error,X)\n",
        "\n",
        "    print(f\"pesos= {w}\")\n",
        "    print(f\"error= {error}\")\n",
        "    b = b + lr*error\n",
        "\n",
        "    print(f\"Sesgo : {b}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 453,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 7.61911086e-06 -6.77200245e-02 -4.33109204e-01  4.99136591e-01]\n"
          ]
        }
      ],
      "source": [
        "print(b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 454,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.4331206 , 0.06773142])"
            ]
          },
          "execution_count": 454,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "w"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 455,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 0],\n",
              "       [0, 1],\n",
              "       [1, 0],\n",
              "       [1, 1]])"
            ]
          },
          "execution_count": 455,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 452,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[7.61911086e-06 1.13934288e-05 1.13935777e-05 9.99988606e-01]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "prediccion = np.dot(X,w) + b\n",
        "\n",
        "print(prediccion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<p><a name=\"Perceptron\"></a></p>\n",
        "\n",
        "### 1.1. Tipos de perceptrones\n",
        "\n",
        "* Perceptrón de una sola capa\n",
        "* Perceptrón multicapa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<p><a name=\"Analogia\"></a></p>\n",
        "\n",
        "## 2. Descenso del grandiente"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Función de perdida\n",
        "\n",
        "La función de perdida mide que tan lejos se encuentran nuestras predicciones de los valores a los que tenemos que llegar. \n",
        "Para el siguiente ejemplo usaremos una función muy común que es la función de error cuadratico medio.\n",
        "\n",
        "\n",
        "$L(w,b) = \\frac{1}{N}\\sum\\limits_{i=0}^{N-1}(y_{pred}^{(i)} - y_{target}^{(i)})^2$\n",
        "\n",
        "donde N es el número de muestras, $y_{pred}^{(i)}$ es el valor de la predicción y  $y_{target}^{(i)}$ es el valor de referencia.\n",
        "\n",
        "**Gradiente**\n",
        "Usando la regla de la cadena en derivadas. El resultado de las derivadas parciales para la función de pesos y sesgos es:\n",
        "\n",
        "$\\frac{\\partial L}{\\partial w_{jk}} = \\frac{1}{N}\\sum\\limits_{i=0}^{N-1} (y_{pred}^{(i)} - y_{target}^{(i)}) \\frac{\\partial y_{pred}^{(i)}}{\\partial w_{jk}}$\n",
        "\n",
        "$\\frac{\\partial L}{\\partial b_{j}} = \\frac{1}{N}\\sum\\limits_{i=0}^{N-1} (y_{pred}^{(i)} - y_{target}^{(i)}) \\frac{\\partial y_{pred}^{(i)}}{\\partial b_{j}}$\n",
        "\n",
        "donde  $w_{jk}$ es el peso del nodo de  k a j y $b_{j}$ es el sesgo del nodo j.\n",
        "\n",
        "\n",
        "**Actualizar pesos**\n",
        "\n",
        "\n",
        "$w_{jk} := w_{jk} - \\alpha \\frac{\\partial L}{\\partial w_{jk}}$\n",
        "\n",
        "$b_{j} := b_{j} - \\alpha \\frac{\\partial L}{\\partial b_{j}}$\n",
        "\n",
        "Donde α is the tasa de aprendizaje. Esta actualiza los pesos/sesgos en una dirección negativa del gradiente para minimizar los valores de perdida.\n",
        "\n",
        "En resumen, calculamos la función de pérdida, las derivadas de la función de pérdida para obtener los gradientes y actualizamos los parámetros utilizando los gradientes. Este proceso se aplica a todos los pesos y sesgos de la red."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Generalidades\n",
        "\n",
        "\n",
        "\n",
        "El producto punto entre dos vectores \n",
        "$ \\mathbf{a}$ y $\\mathbf{b}$ se denota como $\\mathbf{a} \\cdot \\mathbf{b} $\n",
        "\n",
        " y se calcula mediante la siguiente fórmula:\n",
        "\n",
        "$\n",
        "\\mathbf{a} \\cdot \\mathbf{b} = \\sum_{i=1}^{n} a_i b_i\n",
        "$\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "primera entrada [1 0 1] la prediccion es: 0\n",
            "epoca numero 0\n",
            "prediccion: -0.19999999999999996\n",
            "prediccion: -0.19999999999999996\n",
            "prediccion: -0.5599999999999999\n",
            "prediccion: 0.6160000000000001\n",
            "prediccion: 0.17279999999999995\n",
            "prediccion: 0.17552\n",
            "error para todos los pesos 2.6561231104\n",
            "epoca numero 1\n",
            "prediccion: 0.14041599999999999\n",
            "prediccion: 0.3066464\n",
            "prediccion: -0.34513824\n",
            "prediccion: 1.006637344\n",
            "prediccion: 0.4785034751999999\n",
            "prediccion: 0.26700416768\n",
            "error para todos los pesos 0.9628701776715985\n",
            "epoca numero 2\n",
            "prediccion: 0.213603334144\n",
            "prediccion: 0.5347420299776\n",
            "prediccion: -0.26067345110016\n",
            "prediccion: 1.1319428845096962\n",
            "prediccion: 0.6274723921901568\n",
            "prediccion: 0.25433999330650114\n",
            "error para todos los pesos 0.5509165866836797\n",
            "epoca numero 3\n",
            "prediccion: 0.20347199464520088\n",
            "prediccion: 0.6561967149569552\n",
            "prediccion: -0.221948503950995\n",
            "prediccion: 1.166258650532124\n",
            "prediccion: 0.7139004922542389\n",
            "prediccion: 0.21471099528371604\n",
            "error para todos los pesos 0.36445836852222424\n",
            "epoca numero 4\n",
            "prediccion: 0.17176879622697283\n",
            "prediccion: 0.7324724146523222\n",
            "prediccion: -0.19966478845083285\n",
            "prediccion: 1.1697769945341199\n",
            "prediccion: 0.7719890116601171\n",
            "prediccion: 0.17297997428859369\n",
            "error para todos los pesos 0.2516768662079895\n"
          ]
        }
      ],
      "source": [
        "weights = np.array([0.5,0.48,-0.7])\n",
        "\n",
        "\n",
        "\n",
        "streetlights = np.array([\n",
        "    [1,0,1],\n",
        "    [0,1,1],\n",
        "    [0,0,1],\n",
        "    [1,1,1],\n",
        "    [0,1,1],\n",
        "    [1,0,1]\n",
        "\n",
        "])\n",
        "\n",
        "\n",
        "walk_vs_stop = np.array([0,1,0,1,1,0]) # cuando es cero no puede caminar\n",
        "\n",
        "input = streetlights[0]\n",
        "goal_prediction = walk_vs_stop[0]\n",
        "\n",
        "\n",
        "print(f\"primera entrada {input} la prediccion es: {goal_prediction}\")\n",
        "\n",
        "epoch = 5\n",
        "lr= 0.1\n",
        "\n",
        "for i in range(epoch):\n",
        "    print(f\"epoca numero {i}\")\n",
        "    error_for_all_weigths = 0\n",
        "    for r_index in range(len(walk_vs_stop)):\n",
        "        input = streetlights[r_index]\n",
        "        #         goal prediction\n",
        "        goal_prediction = walk_vs_stop[r_index]\n",
        "        prediction = input.dot(weights)\n",
        "        #prediction = np.dot(input,weights)\n",
        "        error = (goal_prediction - prediction)**2 \n",
        "        error_for_all_weigths = error_for_all_weigths + error\n",
        "\n",
        "        delta = prediction - goal_prediction\n",
        "\n",
        "        weights = weights - lr*(input*delta)\n",
        "        print(f\"prediccion: {prediction}\")\n",
        "    print(\"error para todos los pesos\", error_for_all_weigths )\n",
        "\n",
        "    #print(f\"parametro de entrada: {input} meta de prediccion {goal_prediction} error para todos los pesos {error_for_all_weigths}\")\n",
        "    \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Backpropagation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " La técnica de backpropagation ajusta los pesos y sesgos para minimizar la diferencia entre las salidas y las entradas.\n",
        "\n",
        " El algoritmo utiliza una técnica de optimización matemática llamada gradiente descendente, que permite ajustar los pesos y sesgos de la red para minimizar el error. El proceso de ajuste se realiza en dos fases: en la propagación hacia adelante (forward propagation), se calcula la salida de la red para una entrada dada, y en la propagación hacia atrás (back propagation) se ajustan los pesos y sesgos de la red para minimizar el error.\n",
        "<br>\n",
        "\n",
        "**Propagación hacia adelante:**  En esta fase, se introducen los datos de entrada en la red neuronal y se propagan a través de las capas ocultas hasta la capa de salida. En esta capa, se calcula la salida de la red.<br>\n",
        "**Propagación hacia atrás:** En esta fase, se calcula el error entre la salida de la red y la salida deseada. Luego, se propaga este error hacia atrás a través de la red neuronal, desde la capa de salida hacia las capas ocultas. Durante la propagación hacia atrás, se calcula la derivada parcial del error con respecto a cada peso y sesgo de la red.<br>\n",
        "A partir de estas derivadas parciales, se actualizan los pesos y sesgos de la red utilizando la técnica de gradiente descendente. La idea detrás del gradiente descendente es ajustar los pesos y sesgos de la red de manera que minimicen el error en cada época de entrenamiento. El algoritmo utiliza la derivada del error con respecto a cada peso y sesgo para determinar la dirección y magnitud del ajuste."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Este código implementa un ejemplo simple de entrenamiento de una red neuronal mediante el algoritmo de retropropagación (backpropagation). El objetivo de esta red neuronal es predecir si una persona debería caminar o detenerse en función de las señales del semáforo en una intersección.\n",
        "\n",
        "Aquí tienes un desglose paso a paso del código junto con las fórmulas matemáticas involucradas:\n",
        "\n",
        "Importar bibliotecas y configurar semilla aleatoria:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "np.random.seed(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se importa la biblioteca NumPy para realizar cálculos numéricos y se establece una semilla aleatoria para reproducibilidad.\n",
        "\n",
        "Definir funciones de activación:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "def relu(x):\n",
        "    return (x > 0) * x\n",
        "\n",
        "def relu2deriv(output):\n",
        "    return output > 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se definen dos funciones: relu, que implementa la función de activación ReLU (Rectified Linear Unit), y relu2deriv, que devuelve la derivada de ReLU respecto a su entrada.\n",
        "\n",
        "Configurar parámetros de la red neuronal:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "alpha = 0.2\n",
        "hidden_size = 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "alpha es la tasa de aprendizaje que controla el tamaño de los pasos en la actualización de los pesos durante el entrenamiento. hidden_size es el número de neuronas en la capa oculta de la red.\n",
        "\n",
        "Inicializar pesos aleatorios:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "weights_0_1 = 2 * np.random.random((3, hidden_size)) - 1\n",
        "weights_1_2 = 2 * np.random.random((hidden_size, 1)) - 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se inicializan aleatoriamente los pesos de las conexiones entre la capa de entrada y la capa oculta (weights_0_1) y entre la capa oculta y la capa de salida (weights_1_2).\n",
        "\n",
        "Definir los datos de entrada y las etiquetas de salida:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "streetlights = np.array([[1, 0, 1],\n",
        "                         [0, 1, 1],\n",
        "                         [0, 0, 1],\n",
        "                         [1, 1, 1]])\n",
        "\n",
        "walk_vs_stop = np.array([[1, 1, 0, 0]]).T\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "streetlights representa las señales del semáforo para cada intersección, donde cada fila es una instancia y cada columna corresponde a una señal. walk_vs_stop son las etiquetas de salida correspondientes, donde 1 representa \"caminar\" y 0 representa \"detenerse\".\n",
        "\n",
        "Ciclo de entrenamiento:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error:0.6342311598444467\n",
            "Error:0.35838407676317513\n",
            "Error:0.0830183113303298\n",
            "Error:0.006467054957103705\n",
            "Error:0.0003292669000750734\n",
            "Error:1.5055622665134859e-05\n"
          ]
        }
      ],
      "source": [
        "for iteration in range(60):\n",
        "    layer_2_error = 0\n",
        "    for i in range(len(streetlights)):\n",
        "        layer_0 = streetlights[i:i+1]\n",
        "        layer_1 = relu(np.dot(layer_0, weights_0_1))\n",
        "        layer_2 = np.dot(layer_1, weights_1_2)\n",
        "\n",
        "        layer_2_error += np.sum((layer_2 - walk_vs_stop[i:i+1]) ** 2)\n",
        "\n",
        "        layer_2_delta = (walk_vs_stop[i:i+1] - layer_2)\n",
        "        layer_1_delta = layer_2_delta.dot(weights_1_2.T) * relu2deriv(layer_1)\n",
        "\n",
        "        weights_1_2 += alpha * layer_1.T.dot(layer_2_delta)\n",
        "        weights_0_1 += alpha * layer_0.T.dot(layer_1_delta)\n",
        "\n",
        "    if iteration % 10 == 9:\n",
        "        print(\"Error:\" + str(layer_2_error))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Este ciclo es el núcleo del entrenamiento de la red neuronal. Aquí está lo que sucede en cada iteración:\n",
        "\n",
        "Se calcula la salida de la capa oculta (layer_1) aplicando la función ReLU a la entrada ponderada (np.dot(layer_0, weights_0_1)).\n",
        "Se calcula la salida de la capa de salida (layer_2) como el producto escalar entre layer_1 y weights_1_2.\n",
        "Se calcula el error acumulado en esta iteración sumando el cuadrado de las diferencias entre las salidas predichas (layer_2) y las etiquetas reales (walk_vs_stop).<br>\n",
        "Se calcula layer_2_delta, que es la diferencia entre las salidas reales y las predichas en la capa de salida.\n",
        "Se calcula layer_1_delta, que es el producto del delta de la capa de salida y los pesos weights_1_2 transpuestos, multiplicado por la derivada de la función de activación ReLU aplicada a layer_1.<br>\n",
        "Se actualizan los pesos de weights_1_2 y weights_0_1 utilizando el algoritmo de descenso de gradiente (gradiente descendente) multiplicado por la tasa de aprendizaje (alpha).<br>\n",
        "Cada 10 iteraciones, se imprime el error acumulado en la capa de salida.<br>\n",
        "El código entrena una red neuronal de dos capas (una capa oculta y una capa de salida) para predecir si una persona debería caminar o detenerse en función de las señales del semáforo en una intersección. Utiliza la función de activación ReLU y el algoritmo de retropropagación para ajustar los pesos de la red en cada iteración, minimizando así el error entre las predicciones y las etiquetas reales.<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error:0.6342311598444467\n",
            "Error:0.35838407676317513\n",
            "Error:0.0830183113303298\n",
            "Error:0.006467054957103705\n",
            "Error:0.0003292669000750734\n",
            "Error:1.5055622665134859e-05\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "np.random.seed(1)\n",
        "\n",
        "def relu(x):\n",
        "    return (x > 0) * x # returns x if x > 0\n",
        "                       # return 0 otherwise\n",
        "\n",
        "def relu2deriv(output):\n",
        "    return output>0 # returns 1 for input > 0\n",
        "                    # return 0 otherwise\n",
        "\n",
        "\n",
        "\n",
        "alpha = 0.2\n",
        "hidden_size = 4\n",
        "\n",
        "weights_0_1 = 2*np.random.random((3,hidden_size)) - 1\n",
        "weights_1_2 = 2*np.random.random((hidden_size,1)) - 1\n",
        "\n",
        "\n",
        "streetlights = np.array( [[ 1, 0, 1 ],\n",
        "                          [ 0, 1, 1 ],\n",
        "                          [ 0, 0, 1 ],\n",
        "                          [ 1, 1, 1 ] ] )\n",
        "\n",
        "walk_vs_stop = np.array([[ 1, 1, 0, 0]]).T\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for iteration in range(60):\n",
        "   layer_2_error = 0\n",
        "   for i in range(len(streetlights)):\n",
        "      layer_0 = streetlights[i:i+1]\n",
        "      layer_1 = relu(np.dot(layer_0,weights_0_1))\n",
        "      layer_2 = np.dot(layer_1,weights_1_2)\n",
        "\n",
        "      layer_2_error += np.sum((layer_2 - walk_vs_stop[i:i+1]) ** 2)\n",
        "\n",
        "      layer_2_delta = (walk_vs_stop[i:i+1] - layer_2)\n",
        "      layer_1_delta=layer_2_delta.dot(weights_1_2.T)*relu2deriv(layer_1)\n",
        "\n",
        "      weights_1_2 += alpha * layer_1.T.dot(layer_2_delta)\n",
        "      weights_0_1 += alpha * layer_0.T.dot(layer_1_delta)\n",
        "\n",
        "   if(iteration % 10 == 9):\n",
        "      print(\"Error:\" + str(layer_2_error))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "$\\text{Layer 0 (Input Layer): } \\mathbf{layer\\_0} = \\text{streetlights}[i:i+1]$\n",
        "\n",
        "$\\text{Layer 1 (Hidden Layer): } \\mathbf{layer\\_1} = \\text{ReLU}(\\mathbf{layer\\_0} \\cdot \\mathbf{weights\\_0\\_1})$\n",
        "\n",
        "$\\text{Layer 2 (Output Layer): } \\mathbf{layer\\_2} = \\mathbf{layer\\_1} \\cdot \\mathbf{weights\\_1\\_2}$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "$\\text{Layer 2 Error: } \\mathbf{layer\\_2\\_error} += \\sum_{j} (\\mathbf{layer\\_2}[j] - \\text{walk\\_vs\\_stop}[i:i+1][j])^2$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Next"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Redes Neuronales Recurrentes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Redes Convolucionales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
